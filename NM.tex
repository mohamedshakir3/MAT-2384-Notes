\documentclass[openany]{report}
\usepackage[utf8]{inputenc}

\usepackage{stylesheets}
\usepackage{lecture_notes_styles}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\newcommand{\powerset}[0]{\mathcal{P}}

\title{MAT 2384: Numerical Methods Lecture Notes}
\author{Last Updated:}

\begin{document}

\maketitle

\tableofcontents

\chapter{Iterative Methods to Solve The Equation $f(x) = 0$}
Given a continous function $f$, the goal of this chapter is to estimate the solution of the equation $f(x) = 0$ in a certain interval $I$ numerically. 
\begin{theorem}[Intermediate Value Theorem]
    Let $f: [a,b] \rightarrow \real$ be a continous function. Let $y \in \real$ be any value between $f(a)$ and $f(b)$. Then there exists $z \in [a,b]$ such that $f(z) = y$.
\end{theorem}
Bolzano's Theorem is a special case of the Intermediate Value Theorem, which states
\begin{theorem}[Bolzano's Theorem]
    If a continuous function defined on an interval $I$ is sometimes positive and sometimes negative, then it must be 0 at some point. So there exists $x_0 \in I$ such that $f(x_0) = 0$.
\end{theorem}

\begin{proof}
    Without loss of generality, assume $f(a) \leq f(b)$. Let $y \in [f(a), f(b)]$. Set 
    \[S \coloneqq \{x \in [a,b]: f(x) \leq y_0\}\]
    $S$ is a subset of $[a,b]$ so it is bounded, $a \in S$ since $f(a) \leq y_0$. Therefore $S \neq \emptyset$. Thus by completeness, there exists $x_0 \coloneqq \sup S \in [a,b]$. We want $f(x_0) = y_0$. Consider the cases where $f(x_0) = y_0$, $f(x_0) < y_0$, and $f(x_0) \geq y_0$.
    \begin{itemize}
        \item \textbf{Case 1: $f(x_0) = y_0$} This case is trivial since this is the result we want. 
        \item \textbf{Case 2: $f(x_0) < y_0$} Set $\epsilon \coloneqq y_0 - f(x_0)$. Since $f$ is continous at $x_0$, $\exists \delta > 0$ such that 
        \[|x - x_0| < \delta \implies |f(x) - f(x_0)| < \epsilon\]
        Since $f(x_0) < y_0 \leq f(b)$, we can find $x > x_0$ such that $x \in [a,b]$ and $|x-x_0| < \delta$. Then $f(x) < f(x_0) + \epsilon = y_0$. So $x \in S$ by the definition of $S$, but $x > x_0$ which contradicts the fact that $x_0 = \sup S$.
        \item \textbf{Case 3: $f(x_0) > y_0$} Set $\epsilon \coloneqq f(x_0) - y_0$. Since $f$ is continous at $x_0$, $\exists \delta > 0$ such that if $x \in [a,b]$ and $|x-x_0| < \delta$, then $|f(x) - f(x_0)| < \epsilon$. So $f(x) > f(x_0) - \epsilon = y_0$ and $x_0 > a$. We can assume that $x - \delta > a$ since $\delta$ can be arbitrarly small, and we claim $x_0 - \delta$ is an upper bound for $S$. To prove this, if $x > x - \delta$, then either $|x - x_0| < \delta$, in which case $f(x) > f(x_0) - \epsilon = y_0$, or $x > x_0$ then $x \neq S$ since $x_0$ is an upper bound for $S$. Therefore, if $x >  x_0 - \delta$, then $x \neq S$, thus proving the claim. This contradicts that $x_0$ is the supremum of $S$.  
    \end{itemize}
\end{proof}
\noindent
\textbf{Example.} Prove that the equation 
\[2x^3 + 2x - 4 = 0\]
has a unique root in $[0,1]$.
\begin{proof}
    Set $f(x) \coloneqq 3x^2 + 2x - 4$, this function is continuous since it is a polynomial.We have $f(0) = -4 < 0$ and $f(1) = 1 > 0$, so by the intermediate value theorem, there exists $c \in [0,1]$ such that $f(c) = 0$. It follows that $c$ is unique since the polynomial is injective by virtue of $x^3$ and $x$ being injective. 
\end{proof}
\section{Fixed-Point Iteration}
\begin{definition}
    We say that the value $x = r$ is a \emph{fixed point} for a function $g(x)$ if $g(r) = r$.
\end{definition}
\noindent
\textbf{Example.} $g(x) = \frac{5-x^2}{4}$. $r = 1$ is a fixed-point for $g$ since $g(1) = 1$.\\[2ex]
Graphically, fixed-point of $g(x)$ correspond to the intersection of the graph of $g(x)$ and the line $y = x$. Given an equation $f(x) = 0$, we can write it under the form 
\[g(x) = x\]
by isolating one $x$ in the equation.\\[2ex]
\textbf{Example.} $3x^3 + 2x - 5 = 0$. We can write this as 
\[x = \frac{5-3x^3}{2}\]
Set $g(x) \coloneqq \frac{5-3x^3}{2}$. Then $g(x) = x$. Finding a root for $f(x) = 0$ is equivalent to finding a fixed-point for $g(x)$.\\[2ex]
\subsection{Steps to Solving Using Fixed-Point Iteration}
 Start with a first estimation $x_0$ (will be given) of the root, and form the following sequence (known as the \emph{iteration sequence})
    \[x_0, x_1 = g(x_0), x_2 = g(x_1), \dots, x_n = g(x_{n-1})\]
If this sequence converges to a value $a$, then we can prove that $a$ is a fixed-point for $g$, hence a root for $f(x) = 0$.
\begin{theorem}
    Assume that the function $g$ has a fixed-point $s$ on an interval $I$, if 
    \begin{enumerate}[label=(\roman*)]
        \item $g(x)$ is continuous on $I$
        \item $g'(x)$ is continuous on $I$
        \item $|g'(x)| < 1$ for all $x \in I$
    \end{enumerate}
    Then the iteration sequence converges.
\end{theorem}
\noindent
The steps for solving are as follows 
\begin{enumerate}
    \item Start with $f(x) = 0$
    \item Rewrite $f(x) = 0$ under the form $x = g(x)$
    \item Verify that the sequence $x_0, x_1 = g(x_0), x_2 = g(x_1), \dots, x_n = g(x_{n-1})$ converges using the above theorem (or otherwise)
    \item Compute terms of the above sequence and stop when you reach the required accuracy
\end{enumerate}
\textbf{Example.} Consider the equation 
\[x^3 + 12x - 3 = 0\]
\begin{enumerate}
    \item Prove that the equation has a unique root in $[-1.9, 1.9]$
    \item Use the Fixed-Point iteration method to estimate the value of the root to 6 decimal points starting with $x_0 = 1.8$
\end{enumerate}

\textbf{Solution:} Using the steps, we have 
\begin{enumerate}
    \item Set $f(x) \coloneqq x^3 + 12x - 3$. Since $f(x)$ is a polynomial, it is continuous, so by the intermediate value theorem, we have there exists $c \in [-1.9, 1.9]$ such that $f(c) = 0$. $f(x)$ is injective since $x^3$ and $x$ are injective, so $c$ is unique.
    \item Set $g(x) \coloneqq \frac{3-x^3}{12}$.
    \item Checking the conditions of the theorem, $g(x)$ is continuous since it is a polynomial, $g'(x) = -\frac{x^2}{4}$ is continuous since it is a polynomial. Then 
    \[|g'(x)| = \frac{x^2}{4} \leq \frac{1.9^2}{4} = 0.902 < 1\]
    Therefore, the sequence converges. 
    \item We have to calculate the terms of the iteration sequence, 
    \begin{align*}
        &x_0 = 1.8\\
        &x_1 = g(x_0) = \frac{3-1.8^2}{12} = -0.236000\\
        &x_2 = g(x_1) = \frac{3 - (0.236)^2}{12} = 0.251095\\
        &x_3 = g(x_2) = \frac{3 - (0.251095)^2}{12} = 0.24861\\
        &x_4 = g(x_3) = \frac{3 - (0.24861)^2}{12} = 0.248718\\
        &x_5 = g(x_4) = \frac{3 - (0.248718)^2}{12} = 0.248718\\
    \end{align*}
    We stop when 2 consecutive terms agree on the first 6 decimal points. So the root is $0.248718$ correct to 6 decimal points.
\end{enumerate}
\section{Newton's Method}
Newton's method is a technique for solving equations of the form $f(x) = 0$ by successive approximation. The idea is to pick an initial guess $x_0$ such that $f(x_0)$ is reasonably close to 0. We then find the equation of the line tangent to $y = f(x)$ at $x = x_0$, and determine where this tangent line intersects the $x$ axis at the new point $x_1$. So, 
\[x_1 = x_0 - \frac{f(x_0)}{f'(x_0)}\]
We then find the equation of the line tangent to $y = f(x)$ at $x = x_1$, and repeat this process, so we have 
\[x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}\]
\textbf{Example.} Using Newton's method, estimate the value of the root of the equation 
\[x^3 + 12x - 3 = 0\]
on $[0,2]$. Start by showing that the equation has a unique root on $[0,2]$, then approximate (to 6 decimal places) with the starting point $x_0 = 1.8$.\\[2ex]
\textbf{Solution.} We have $f(x) = x^3 + 12x - 3$, and 
\[f(0) = -3 \text{ and } f(2) = 29\]
Therefore by the intermediate value theorem, there exists $c \in [0,2]$ such that $f(c) = 0$. $f(x)$ is injective since $f'(x) = 2x^2 + 12$ is striclty increasing on $[0,2]$, so $c$ is unique. Now using Newton's method, 
\[x_0 = 1.8\]
\[x_1 = x_0 - \frac{f(x_0)}{f'(x_0)} = 0.675138\]
\[x_2 = x_1 - \frac{f(x_1)}{f'(x_1)} = 0.270469\]
\[x_3 = x_2 - \frac{f(x_2)}{f'(x_2)} = 0.248748\]
\[x_4 = x_3 - \frac{f(x_3)}{f'(x_3)} = 0.248718\]
\[x_5 = x_4 - \frac{f(x_4)}{f'(x_4)} = 0.248718\]
Therefore, the our root is $0.248718$ correct to 6 decimal places.\\[3ex]
\textbf{Example.} Consider the equation 
\[x^3 - 2x - 5 = 0\]
\begin{enumerate}[label=(\roman*)]
    \item Prove that the equation has a unique root in $[2,3]$
    \item Starting with $x_0 = 3$, estimate the root of the equation to 6 decimal places using Newton's method.
\end{enumerate}
\textbf{Solution.} 
\begin{enumerate}[label=(\roman*)]
    \item We have $f(2) = -1$ and $f(3) = 16$, therefore by the intermediate value theorem there exists $c \in [2,3]$ such that $f(c) = 0$. $f'(x) = 3x^2 - 2$ is injective since if $f(x_1) = f(x_2)$, then we have
    \begin{align*}
        &f(x_1) = f(x_2)\\
        \implies& x_1^3 - 2x_1 - 5 = x_2^3 - 2x_2 - 5\\
        \implies& x_1^3 - 2x_1 = x_2^3 - 2x_2\\
    \end{align*} 
    Then $x^3$ and $x$ are injective functions, so we must have that $x_1 = x_2$ and therefore the root is unique. Alternatively, we can look at the derivative on its interval, 
    \begin{align*}
        2 \leq x \leq 3\\
        4 \leq x^2 \leq 9\\
        12 \leq 3x^2 \leq 27\\
        10 \leq 3x^2 - 2 \leq 25\\
    \end{align*}
    Therefore the derivative is positive so the function is strictly increasing, and thus injective.
    \item Starting with $x_0 = 3$, using Newton's method we get 
    \[x_1 = x_0 - \frac{f(x_0)}{f'(x_0)} = 3 - \frac{3^3 - 2(3) - 5}{3(3)^2 - 2} = 2.600000\]
    \[x_2 = 2.6 - \frac{f(2.6)}{f'(2.6)} = 2.127197\]
    \[x_3 x_2 - \frac{f(2.127197)}{f'(2.127197)} = 2.0945136\]
    \[x_4 = x_3 - \frac{f(2.094552)}{f'(2.094552)} = 2.094552\]
    \[x_5 = x_4 - \frac{f(x_4)}{f'(x_4)} = 2.094551 \]
    \[x_6 = x_5 - \frac{f(x_5)}{f'(x_5)} = 2.094551\]
    Therefore, we have $x \approx 2.094551$ correct to 6 decimal places.
\end{enumerate}
\noindent
\textbf{Example.} Use Newton's Method with $x_0 = 2$ to estimate the value of $\sqrt[3]{7.9}$ correct to 6 decimal places.\\[2ex]
\textbf{Solution.} We can set $x \coloneqq \sqrt[3]{7.9}$, so we have $x^3 - 7.9 = 0$. Then this can be solved the same as the previous examples.
\section{The Secant Method}
The tangent line to the curve of $y = f(x)$ with the point of tangency $(x0, f(x0)$ was used in Newton's approach. The graph of the tangent line about $x = \alpha$ is essentially the same as the graph of $y = f(x)$ when $x_0 \approx \alpha$. The root of the tangent line was used to approximate $\alpha$. Consider employing an approximating line based on interpolation. Given 2 root estimations $x_0$ and $x_1$, then we have a linear function
\[q(x) = a_0 + a_1x\]
with $q(x_0) = f(x_0)$, and $q(x_1) = f(x_1)$. This line is alo known as the secant line, with the formula 
\[q(x) = \frac{(x_1 - x)f(x_0) + (x-x_0)f(x_1)}{x_1 - x_0}\]
The linear equation $q(x) = 0$ with the root denoted by $x_2$ is given by
\[x_2 = x_1 - f(x_1) \cdot \frac{x_1 - x_0}{f(x_1) - f(x_0)}\]
This equation can now be employed for every term in the sequence, 
\[x_{n+1} = x_n - f(x_n) \cdot \frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1}) } \]
\textbf{Example.} Use the secant method with $x_0 = 2$ and $x_1 = 1.9$ to estimate the root of the equation to 6 decimal places 
\[2\sin x - x = 0\]
\textbf{Solution.} We have $f(x) = 2 \sin x - x$, we can start calculating the terms of the sequnce 
\[x_2 = x_1 - f(x_1)\frac{x_1 - x_0}{f(x_1) - f(x_0)} = 1.9 - (2\sin(1.9) - 1.9)\frac{1.9 - 2}{(2 \sin(1.9) - 1.9) - (2 \sin (2) - 2)} = 1.895747\]
\[x_3 = x_2 - f(x_2)\frac{x_2 - x_1}{f(x_2) - f(x_1)} = 1.895747\]
Therefore the root is $x \approx 1.895747$ correct to 6 decimal places.
\chapter{Interpolation}
Given a set of $n+1$ data points $(x_0, f_0), \ldots, (x_n, f_n)$ where 
\[f_i = f(x_i)\]
for some unkown function $f$, the goal is to  find a \emph{polynomial} function of degree $n$, say $p_n(x)$, where its graph goes through all the datapoints. We then can use the approximation $f(x) \approx p_n(x)$.
\begin{theorem}
    Given a collection of $n+1$ data points $(x_0, f_0), \ldots, (x_n, f_n)$ in the cartesian plane such that 
    \[x_0 < x_1 < x_2 < \cdots < x_n\]
    Then there exists a unique polynomial of degree $\leq n$ such that 
    \[p_n(x_i) = f_i \ \forall i \in \{0, 1, \ldots, n\}\]
\end{theorem}
If we use the approximation $f(x) \approx p_n(x)$, then the absolute error ($|f(x) - p_n(x)|$) is given by the following theorem. 
\begin{theorem}[Error Formula]
    The error formula with the above notation is 
    \[|f(x) - p_n(x)| = |(x-x_0)(x-x_1)\cdots(x-x_n)\frac{f^{(n+1)}(t)}{(n+1)!}\]
\end{theorem}
\end{document} 